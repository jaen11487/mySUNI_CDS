{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network, 순환 신경망\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 실습, 다음 수 예측( Many to One)\n",
    "* RNN 구조를 직접 구현해서 다음 숫자 예측하는 실습    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입출력 데이타 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[[0.0], [0.1], [0.2], [0.3]],\n",
       " [[0.1], [0.2], [0.3], [0.4]],\n",
       " [[0.2], [0.3], [0.4], [0.5]],\n",
       " [[0.3], [0.4], [0.5], [0.6]],\n",
       " [[0.4], [0.5], [0.6], [0.7]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[0.4], [0.5], [0.6], [0.7], [0.8]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "step_size = 4\n",
    "batch_size = 5\n",
    "\n",
    "x = [ [[i/10] for i in range(j, j+step_size)] for j in range(batch_size)]\n",
    "y = [[ (i+step_size) /10] for i in range(batch_size)]\n",
    "display(\"x\", x, \"y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF Keras Model을 이용한 다음 수 예측 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "prediction: [0.39952955 0.49973935 0.60083854 0.701282   0.7985467 ]\n"
     ]
    }
   ],
   "source": [
    "element_size = 1\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(10, input_shape=[step_size, element_size]),\n",
    "    tf.keras.layers.Dense(element_size)\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x, y, epochs=1000, verbose=0)\n",
    "pred = model.predict(x)\n",
    "print(f'prediction: {tf.squeeze(pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanila RNN 실습2, Many to Many\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입출력 데이타 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[[0.0], [0.1], [0.2], [0.3]],\n",
       " [[0.1], [0.2], [0.3], [0.4]],\n",
       " [[0.2], [0.3], [0.4], [0.5]],\n",
       " [[0.3], [0.4], [0.5], [0.6]],\n",
       " [[0.4], [0.5], [0.6], [0.7]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[[0.1], [0.2], [0.3], [0.4]],\n",
       " [[0.2], [0.3], [0.4], [0.5]],\n",
       " [[0.3], [0.4], [0.5], [0.6]],\n",
       " [[0.4], [0.5], [0.6], [0.7]],\n",
       " [[0.5], [0.6], [0.7], [0.8]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "step_size = 4\n",
    "batch_size = 5\n",
    "\n",
    "x = [ [[i/10] for i in range(j, j+step_size)] for j in range(batch_size)]\n",
    "y = [ [[i/10] for i in range(j+1, j+step_size+1)] for j in range(batch_size)]\n",
    "display(\"x\", x, \"y\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF Keras를 이용한 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_20 (SimpleRNN)    (None, 4, 10)             120       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4, 1)              11        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "prediction: [[0.2834577  0.21673763 0.27802214 0.38358343]\n",
      " [0.2944024  0.31542468 0.39945063 0.5002965 ]\n",
      " [0.30445662 0.4112241  0.51065373 0.60875326]\n",
      " [0.3132205  0.5031215  0.60719633 0.7082859 ]\n",
      " [0.32035115 0.5903807  0.68736416 0.7984788 ]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(10, input_shape=[step_size, element_size], return_sequences=True),\n",
    "    tf.keras.layers.Dense(element_size)\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x, y, epochs=1000, verbose=0)\n",
    "pred = model.predict(x)\n",
    "print(f'prediction: {tf.squeeze(pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text 데이타 실습, One-hot Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입출력 데이타 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:hihello\n",
      "char2idx:{'e': 0, 'l': 1, 'i': 2, 'o': 3, 'h': 4}, idx2char:{0: 'e', 1: 'l', 2: 'i', 3: 'o', 4: 'h'}\n",
      "x:hihell, y:ihello\n",
      "x_idx:[4, 2, 4, 0, 1, 1], y_idx:[2, 4, 0, 1, 1, 3]\n",
      "x_enc: [[[0. 0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]]] (1, 6, 5)\n",
      "y_enc: [[[0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]] (1, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = \"hihello\"\n",
    "\n",
    "voca = set(sentence) #unique charters\n",
    "char2idx = {c:i for i,c in enumerate(voca)}\n",
    "idx2char = {i:c for i, c in enumerate(voca)}\n",
    "print(f'sentence:{sentence}')\n",
    "print(f'char2idx:{char2idx}, idx2char:{idx2char}')\n",
    "\n",
    "x = sentence[:-1] #\"hihell\"\n",
    "y = sentence[1:] #\"ihello\"\n",
    "print(f'x:{x}, y:{y}')\n",
    "\n",
    "n_class = len(voca)  #example size\n",
    "n_time_steps = len(x) #input sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "''' convert char to integer '''\n",
    "x_idx = [char2idx[c] for c in x]\n",
    "y_idx = [char2idx[c] for c in y]\n",
    "print(f\"x_idx:{x_idx}, y_idx:{y_idx}\")\n",
    "\n",
    "''' one-hot encoding'''\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM을 이용한 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 6, 5)              220       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6, 5)              30        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 5)              0         \n",
      "=================================================================\n",
      "Total params: 250\n",
      "Trainable params: 250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[[5.7636272e-02 3.2721840e-02 8.1942415e-01 6.9915815e-03 8.3226211e-02]\n",
      "  [1.7295246e-01 1.0505311e-02 6.7424826e-02 2.5534625e-03 7.4656397e-01]\n",
      "  [7.7144426e-01 4.3208193e-02 2.9042009e-02 1.2520365e-03 1.5505353e-01]\n",
      "  [4.9345892e-02 9.1402274e-01 9.5988065e-03 2.2867098e-02 4.1654333e-03]\n",
      "  [9.9146655e-03 9.0968257e-01 3.2896472e-03 7.6471224e-02 6.4188422e-04]\n",
      "  [1.2772365e-03 1.1706970e-01 3.4941558e-03 8.7378478e-01 4.3741260e-03]]] [2 4 0 1 1 3]\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(hidden_size, input_shape=(n_time_steps, n_class), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dense(hidden_size))\n",
    "model.add(tf.keras.layers.Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "n_epochs = 1000\n",
    "history = model.fit(x_enc, np.reshape(y_idx, (1,6,1)), epochs=n_epochs, verbose=0)\n",
    "\n",
    "preds = model.predict(x_enc)\n",
    "print(preds, np.squeeze(np.argmax(preds, axis=2)))\n",
    "print([idx2char[i] for i in np.squeeze(np.argmax(preds, axis=2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Embedding Layer 실습\n",
    "* 긍정/부정 어휘 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size : 15\n",
      "integer encoded: [[2, 3, 1, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 1]]\n",
      "max_len: 4\n",
      "padded : [[ 2  3  1  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14  1  0  0]]\n",
      "embedding init : [[[-0.03830038 -0.00979317]\n",
      "  [ 0.04742971  0.03679741]\n",
      "  [-0.02656862 -0.04510809]\n",
      "  [-0.03885192 -0.032944  ]]\n",
      "\n",
      " [[-0.00261912  0.04927878]\n",
      "  [ 0.03732674 -0.04802374]\n",
      "  [ 0.03983864  0.02522461]\n",
      "  [ 0.03983864  0.02522461]]\n",
      "\n",
      " [[-0.02871524 -0.04586512]\n",
      "  [-0.00109534 -0.03157889]\n",
      "  [ 0.03983864  0.02522461]\n",
      "  [ 0.03983864  0.02522461]]]\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 4, 2)              30        \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "embedding last : [[[-0.44584236  0.38378528]\n",
      "  [-0.4085907  -0.3049673 ]\n",
      "  [-0.6060485  -0.47585234]\n",
      "  [-0.37545377  0.3680631 ]]\n",
      "\n",
      " [[ 0.49695083 -0.43553331]\n",
      "  [ 0.5856042   0.37878647]\n",
      "  [ 0.46805128  0.45514685]\n",
      "  [ 0.46805128  0.45514685]]\n",
      "\n",
      " [[ 0.46793577 -0.5277508 ]\n",
      "  [ 0.5443586   0.39237097]\n",
      "  [ 0.46805128  0.45514685]\n",
      "  [ 0.46805128  0.45514685]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "corpus = ['very good nice quality', \n",
    "             'stop lies',\n",
    "             'ugly terrible', \n",
    "             'excellent work', \n",
    "             'adorable lovely', \n",
    "             'bad',\n",
    "             'greate nice']\n",
    "\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1] #1 :pos, 0 : neg\n",
    "\n",
    "t = tf.keras.preprocessing.text.Tokenizer()\n",
    "t.fit_on_texts(corpus)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "print(f'vocab_size : {vocab_size}')\n",
    "\n",
    "X_encoded = t.texts_to_sequences(corpus)\n",
    "print(f'integer encoded: {X_encoded}')\n",
    "\n",
    "max_len=max(len(l) for l in X_encoded)\n",
    "print(f'max_len: {max_len}')\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
    "y_train=np.array(y_train)\n",
    "print(f'padded : {X_train}')\n",
    "\n",
    "embd = tf.keras.layers.Embedding(vocab_size, 2, input_length=max_len)\n",
    "print(f'embedding init : {embd(X_train)[:3]}')\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(embd) \n",
    "model.add(tf.keras.layers.Flatten()) # Dense의 입력으로 넣기위함.\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=500, verbose=0)\n",
    "\n",
    "print(f'embedding last : {embd(X_train)[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46805128  0.45514685]\n",
      " [-0.6060485  -0.47585234]\n",
      " [-0.44584236  0.38378528]\n",
      " [-0.4085907  -0.3049673 ]\n",
      " [-0.37545377  0.3680631 ]\n",
      " [ 0.49695083 -0.43553331]\n",
      " [ 0.5856042   0.37878647]\n",
      " [ 0.46793577 -0.5277508 ]\n",
      " [ 0.5443586   0.39237097]\n",
      " [-0.55632174  0.4738349 ]\n",
      " [-0.5174578  -0.45235133]\n",
      " [-0.5468264   0.5264467 ]\n",
      " [-0.5186092  -0.47502556]\n",
      " [ 0.46115583 -0.51825726]\n",
      " [-0.4813648   0.47686896]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAI/CAYAAABAoBw9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXRW1aGw8WcToDIoDqBFikJbiwMyhCCGMYCCWitaRyoy+AF6nW1VRJeK0oq3ttarbaVawbGFFpwu6i2CRsBGJVGkUq5gr6lauFdwQEAUCPv7IyEyBInk3Rng+a3FIu95d87Z56yoj+ec9yTEGJEkSVIa9Wp6ApIkSbszY0uSJCkhY0uSJCkhY0uSJCkhY0uSJCkhY0uSJCmh+jU9ga/SvHnz2KZNm5qehiRJ0k4VFRWtjDG22HZ5rY6tNm3aUFhYWNPTkCRJ2qkQwj8rWu5lREmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMrVrkgQce4JJLLkm+rqZNm2ZkG5IkaeeMrTps48aNNT0FSZK0E8ZWNTr11FPp0qULRx11FPfeey8AkydP5nvf+x59+vThpZdeKh/7z3/+k/79+9OhQwf69+/Pu+++C8Dw4cP58Y9/TN++fRkzZgyvvvoq3bt3p3PnznTv3p233nqrfB3vvfceJ5xwAu3atePmm2+ucE633347Xbt2pUOHDtx0000J916SpD1T/ZqewJ5k0qRJ7L///qxbt46uXbvy/e9/n5tuuomioiKaNWtG37596dy5MwCXXHIJQ4cOZdiwYUyaNInLLruMJ554AoAlS5Ywa9YssrKy+PTTT5kzZw7169dn1qxZXHfddUyfPh2AV199lTfffJPGjRuXby8nJ6d8PjNnzmTp0qW8+uqrxBg55ZRTmDNnDr17967+gyNJ0m7K2KpGd911F48//jhQetbp4YcfJi8vjxYtWgBw9tlns2TJEgAKCgp47LHHADjvvPO45pprytdz5plnkpWVBcCqVasYNmwYS5cuJYTAhg0byscdf/zxHHDAAQD88Ic/ZN68edvF1syZM8sDb82aNSxdutTYkiQpg4ytapKfn8+sWbMoKCigcePG5OXlcfjhh7N48eJKfX8IofzrJk2alH99ww030LdvXx5//HGKi4vJy8ur8Hsqeh1jZOzYsVxwwQW7sEeSJKkyvGcrsYICmDABXnllFfvttx+NGzfmv//7v3n55ZdZt24d+fn5fPjhh2zYsIE///nP5d/XvXt3pkyZAsCjjz5Kz549K1z/qlWraNWqFVD6CcQtPffcc3z00UesW7eOJ554gh49emz1/sCBA5k0aRJr1qwB4F//+hcffPBBpnZdkiThma2kCgqgf39Yvx4aNDiBTp0m0qFDB9q1a8exxx5Ly5YtGTduHLm5ubRs2ZLs7GxKSkqA0kuO559/PrfffjstWrRg8uTJFW7jmmuuYdiwYdxxxx3069dvq/d69uzJeeedx9tvv82PfvSjrS4hAgwYMIDFixeTm5sLlD4S4pFHHuHAAw9McDQkSdozhRhjTc9hh3JycmJhYWFNT2OXTZgAN9wAJSWQlQXjx8PYsTU9K0mSlEIIoSjGmLPtci8jJpSXBw0bloZWw4alryVJ0p7Fy4gJ5ebC7NmQn18aWmVX6yRJ0h7E2EosN9fIkiRpT+ZlREmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLUmSpISMLX0tCxYs4JlnnqnpaUiSVGcYW3uwjRs3fu3vMbYkSfp66tf0BPT1PfDAAxQWFvLrX/+acePG0bRpU6666qrtxo0fP55HH32U1q1b07x5c7p06cKMGTPo3r07L730Ej179qR169Y899xzvPvuuwDceeed9OjRg1dffZUrrriCdevW0ahRIyZPnkzbtm258cYbWbduHfPmzWPs2LGcfPLJXHrppfztb39j48aNjBs3jkGDBlX3IZEkqdYytnZThYWFTJ8+nddff52NGzeSnZ1Nly5dAPjkk0948cUXyc/P59xzz2Xq1Kn07NmTd999l4EDB7J48WIOP/xw5syZQ/369Zk1axbXXXcd06dP55ZbbikPPYDrrruOfv36MWnSJD755BOOOeYYjjvuOJo0aVKTuy9JUq3hZcSEHnnkEY455hg6derEBRdcwD//+U8OO+wwVq5cyaZNm+jVqxczZ84E4KGHHqJDhw507NiR8847D4AVK1Zw+umn07VrV7p27cpLL730ldv7xz/+wQknnECXLl0466yz6NGjB40aNeLSSy+ladOm/PrXv+aVV17hoIMOAuDaa69l+fLlHH/88bRq1YpTTjmFTz/9lNWrV7Nq1SrOPPNM2rdvz5VXXsmiRYsq3ObMmTO57bbb6NSpE3l5eXz++eflZ8kkSZJntpJZvHgxU6dO5aWXXqJBgwZcdNFFvPjii4wZM4YLL7yQbt26ceSRRzJgwAAWLVrEz372M1566SWaN2/ORx99BMDll1/OlVdeud1Zpx0ZPXo0EydO5LDDDuOKK67gySefLH9v7dq1XHzxxfz5z3/mvvvu46abbuK2225jwIABfPTRRzRq1GirdV166aX07duXxx9/nOLiYvLy8ircZoyR6dOn065du6ofNEmSdkPGViKzZ8+mqKiIrl27ArBu3ToOPPBAxo0bx5///GcmTpzIggULAHj++ec544wzaN68OQD7778/ALNmzeLvf/97+To3n3WqyJo1a/jrX//K979/JmvWQP36n/HBB8v5/PPP2bBhA6tXryaEQOPGjctjDqBFixb8+te/5uqrrwZKb4Dv1KkTq1atolWrVkDpPWKb7b333lvNYeDAgdx9993cfffdhBB4/fXX6dy5c1UPnyRJuw1jK5EYI8OGDWPChAlbLf/ss894//33gdJA2nvvvYkxEkLYbh2bNm2ioKBgu7NOFdm0aRNNmuzL++8vYP16aNgQzj13HB07dmT16tV897vfpVmzZuVz2+yoo46isLCQDh06sHHjRnr37s3EiRO55pprGDZsGHfccQf9+vUrH9+3b9/yy4Zjx47lhhtu4IorrqBDhw7EGGnTpg0zZszYpWMmSdLuyNjKsIICyM+HQw/tz113DeLKK6/kwAMP5KOPPmL16tX84he/4Nxzz+XQQw9l1KhRzJgxg/79+3Paaadx5ZVXcsABB/DRRx+x//77M2DAgArPOlVkn332oUmTtnz88Z/ZtOlMvvgi0qDBQN56axxDhgyhoKCALl26MGrUKJo2bQqUnqX64osvmDp16nbry83NZcmSJeWvx48fD5SedZs/f/5WY3/3u99l4tBJkrRbMrYyqKAA+ven7MzSkYwd+1MGDBjApk2baNCgAXfccQfz58/npZdeIisri+nTpzN58mRGjBjB9ddfT58+fcjKyqJz58488MAD3HXXXVx88cXbnXXakTvueJSzzvo34KfEuIFZs+rTqVM93nnnHU4++WSys7O3Gt+hQwfq169Px44dGT58OFdeeWXiIyRJ0p4nbHlJqbbJycmJhYWFNT2NSpswAW64AUpKICsLxo+HsWOrdw6bz6zl5UFubvVuW5KkPVkIoSjGmLPtcs9sZVBeXum9UpvvmdrBB/iSys01siRJqk2MrQzKzYXZsz2zJEmSvmRsZZhnliRJ0pZ8grwkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSVJCGYmtEMIJIYS3QghvhxCu/YpxXUMIJSGEMzKxXUmStHv75JNP+O1vf1vl9YwcOZK///3vADRt2rTCMcOHD2fatGlV3ta2qhxbIYQs4DfAicCRwOAQwpE7GPfvwF+quk1JkrRn+LqxFWNk06ZNWy0rKSnh97//PUceuV2eVItMnNk6Bng7xvg/Mcb1wBRgUAXjLgWmAx9kYJuSJGkPcO211/KPf/yDTp06cfXVV3P77bfTtWtXOnTowE033QRAcXExRxxxBBdddBHZ2dm89957NG3alBtvvJFu3bpRUFBAXl4ehYWF5ev9yU9+QnZ2Nv3792fFihXbbbeoqIg+ffrQpUsXBg4cyPLly3d5HzIRW62A97Z4/X7ZsnIhhFbAacDEDGxPkiTtIW677Ta+853vsGDBAo4//niWLl3Kq6++yoIFCygqKmLOnDkAvPXWWwwdOpTXX3+dQw89lLVr19K+fXteeeUVevbsudU6165dS3Z2Nq+99hp9+vTh5ptv3ur9DRs2cOmllzJt2jSKioo4//zzuf7663d5H+rv8nd+KVSwLG7z+k5gTIyxJISKhm+xshBGA6MBDjnkkAxMT5Ik7Q5mzpzJzJkz6dy5MwBr1qxh6dKlHHLIIRx66KEce+yx5WOzsrI4/fTTK1xPvXr1OPvsswEYMmQIP/zhD7d6/6233uLNN9/k+OOPB0ovQ7Zs2XKX552J2HofaL3F628By7YZkwNMKQut5sBJIYSNMcYntl1ZjPFe4F6AnJycbaNNtVSMkRgj9er5AVdJUhoxRsaOHcsFF1yw1fLi4mKaNGmy1bK99tqLrKysSq132xNBMUaOOuooCgoKqjbhMpn4L+N84LAQQtsQQkPgHOCpLQfEGNvGGNvEGNsA04CLKgot1bwxY8ZsdSPiuHHj+OUvf1mpa+Tjx4/nyiuvLP/e++67jx//+MfVvg+SpN1DQQHcf//erFy5GoCBAwcyadIk1qxZA8C//vUvPvigcreCz507F4Bly5axadOm8k8d/uEPf9juMmO7du1YsWJFeWxt2LCBRYsW7fJ+VDm2YowbgUso/ZThYuBPMcZFIYQLQwgXVnX9ql7nnHMOU6dOLX/9pz/9iRYtWlTqGvlVV13FU089xYYNGwCYPHkyI0aMqJH9kCTVbQUF0L8/TJhwACtX9uDb327Pc889x49+9CNyc3M5+uijOeOMM1i9evXXWu/BBx9MkyZNWLRoEV26dOH555/nxhtv3GpMw4YNmTZtGmPGjKFjx4506tSJv/71r7u8L5m4jEiM8RngmW2WVXgzfIxxeCa2qTQ6d+7MBx98wLJly1ixYgX77bcfCxcurNQ18iZNmtCvXz9mzJjBEUccwYYNGzj66KNrcnckSXVUfj6sXw8lJZCV9QdGjYKxY0vfu/zyy7cb/+abb271evPZr80aNWpETk4OxcXFtGnThvHjxzNu3DiuvfZaTjrpJL744gsuvvhizjjjDJYvX85ll13Gp59+SklJCRMnTqRXr167vC8ZiS3tXs444wymTZvG//7v/3LOOedQXFxc6WvkI0eO5NZbb+Xwww/3rJYkaZfl5UHDhqXB1bBh6etMu//++2nWrBnz58/niy++oEePHgwYMIDHHnuMgQMHcv3111NSUsJnn31Wpe0YWypXUFD6fxKHH34Ov/nNKFauXMmLL77I3/72N2644QbOPfdcmjZtyr/+9S8aNGhQ4Tq6devGe++9x2uvvcbChQurdwckSbuN3FyYPbv0v0t5eaWvM23mzJksXLiw/P6tVatWsXTpUrp27cr555/Phg0bOPXUU+nUqVOVtmNsCfjy2njp/0EcRcuWqznkkFa0bNmSli1bsnjxYnLLftKbNm3KI488ssNPeZx11lksWLCA/fbbrzp3oVxxcTEnn3wyb775JoWFhTz00EPcdddd5Ofn07BhQ7p3714j85IkfT25uWkia7MYI3fffTcDBw7c7r05c+bw9NNPc95553H11VczdOjQXd6OsSVg62vj69fDyJF/K782DqXXxytzjRxg3rx5W30qsSbl5OSQk5MDQH5+Pk2bNjW2JGkPsvmqzTa/wQco/XTjPffcQ79+/WjQoAFLliyhVatWrFy5klatWjFq1CjWrl3La6+9VqXY8qFIAr68Np6VtevXxj/55BO+973v0ahRI/r3779L8/jZz35Gu3btOO644xg8eDC/+MUvtvoVCytXrqRNmzZA6RmsXr16kZ2dTXZ2doWfFMnPz+fkk0+muLiYiRMn8qtf/YpOnToxd+5c2rZtW/7JyU8//ZQ2bdqUv5Yk1X2br9rccAOsW1f6eksjR47kyCOPJDs7m/bt23PBBRewceNG8vPz6dSpE507d2b69OkVnmz4OjyzJSAz18b33XdflixZsstzKCoqYsqUKbz++uts3LiR7OxsunTpssPxBx54IM899xx77bUXS5cuZfDgwVv93qsttWnThgsvvJCmTZty1VVXAZCXl8fTTz/NqaeeypQpUzj99NN3eC+aJKnu2foTjWvIz4exY9uUX5WpV68et956K7feeutW3zds2DCGDRuWsXkYWyqX+tr4zsydO5fTTjuNxo0bA3DKKad85fgNGzZwySWXsGDBArKysr526I0cOZKf//znnHrqqUyePJn77rtvl+cuSap9quMTjZVhbKlWqeh3Z9avX59NZRfbP//88/Llv/rVrzjooIN444032LRpE3vttdfX2laPHj0oLi7mxRdfpKSkhPbt21dt8pKkWqU6PtFYGd6zpRpXUAATJsC++/bm8ccfZ926daxevZr//M//BEovARYVFQGUfzwXSj+i27JlS+rVq8fDDz9MSUnJV25n77333u5Jw0OHDmXw4ME+E0ySdlO5uaUPQ63JKzfGlmrUljcvXnRRNrm5Z9OpUydOP/308qf1XnXVVdxzzz10796dlStXln/vRRddxIMPPsixxx7LkiVLtnvA6rZ+8IMf8Pjjj5ffIA9w7rnn8vHHHzN48OB0OylJ2qOFGGNNz2GHcnJy4o5ueNbuYcKE0tAqvXkRxo//8tcxjBs3bqsb2lOYNm0aTz75JA8//HCybUiS9gwhhKIYY862y71nSzWqJm9evPTSS3n22Wd55plndj5YkqRd5Jkt1bjND5yryZsXJUmqKs9sqdaq6UdOSJKUkjfIS5IkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJWRsSZIkJZSR2AohnBBCeCuE8HYI4doK3j83hLCw7M9fQwgdM7FdSZKk2q7KsRVCyAJ+A5wIHAkMDiEcuc2wd4A+McYOwHjg3qpuV5IkqS7IxJmtY4C3Y4z/E2NcD0wBBm05IMb41xjjx2UvXwa+lYHtSpIk1XqZiK1WwHtbvH6/bNmO/D/g2QxsV5Ikqdarn4F1hAqWxQoHhtCX0tjqucOVhTAaGA1wyCGHZGB6kiRJNScTZ7beB1pv8fpbwLJtB4UQOgC/BwbFGD/c0cpijPfGGHNijDktWrTIwPQkSZJqTiZiaz5wWAihbQihIXAO8NSWA0IIhwCPAefFGJdkYJuSJEl1QpUvI8YYN4YQLgH+AmQBk2KMi0IIF5a9PxG4ETgA+G0IAWBjjDGnqtuWJEmq7UKMFd5eVSvk5OTEwsLCmp6GJEnSToUQiio6meQT5CVJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhIytiRJkhLKSGyFEE4IIbwVQng7hHBtBe+HEMJdZe8vDCFkZ2K7kiRJtV2VYyuEkAX8BjgROBIYHEI4cpthJwKHlf0ZDdxT1e1KkiTVBZk4s3UM8HaM8X9ijOuBKcCgbcYMAh6KpV4G9g0htMzAtiVJkmq1TMRWK+C9LV6/X7bs646RJEna7WQitkIFy+IujCkdGMLoEEJhCKFwxYoVVZ6cJElSTcpEbL0PtN7i9beAZbswBoAY470xxpwYY06LFi0yMD1JkqSak4nYmg8cFkJoG0JoCJwDPLXNmKeAoWWfSjwWWBVjXJ6BbUuSJNVq9au6ghjjxhDCJcBfgCxgUoxxUQjhwrL3JwLPACcBbwOfASOqul1JkqS6oMqxBRBjfIbSoNpy2cQtvo7AxZnYliRJUl3iE+QlSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISMrYkSZISqlJshRD2DyE8F0JYWvb3fhWMaR1CeCGEsDiEsCiEcHlVtilJklSXVPXM1rXA7BjjYcDsstfb2gj8JMZ4BHAscHEI4cgqbleSJKlOqGpsDQIeLPv6QeDUbQfEGJfHGF8r+3o1sBhoVcXtSpIk1QlVja2DYozLoTSqgAO/anAIoQ3QGXilituVJEmqE+rvbEAIYRbwzQreuv7rbCiE0BSYDlwRY/z0K8aNBkYDHHLIIV9nE5IkSbXOTmMrxnjcjt4LIfxfCKFljHF5CKEl8MEOxjWgNLQejTE+tpPt3QvcC5CTkxN3Nj9JkqTarKqXEZ8ChpV9PQx4ctsBIYQA3A8sjjHeUcXtSZIk1SlVja3bgONDCEuB48teE0I4OITwTNmYHsB5QL8QwoKyPydVcbuSJEl1wk4vI36VGOOHQP8Kli8DTir7eh4QqrIdSZKkusonyEuSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbEmSJCVkbKnWKy4upn379jU9DUmSdomxJUmSlFD9mp6Adj/jx4/n0UcfpXXr1jRv3pwuXbpw3HHHceGFF/LZZ5/xne98h0mTJrHffvuxYMGCCpcXFRVx/vnn07hxY3r27FnTuyRJ0i7zzJYyqrCwkOnTp/P666/z2GOPUVhYCMDQoUP593//dxYuXMjRRx/NzTff/JXLR4wYwV133UVBQUGN7YskSZlgbCmj5s2bx6BBg2jUqBF77703P/jBD1i7di2ffPIJffr0AWDYsGHMmTOHVatWVWr5eeedV2P7I0lSVRlbyqgYY0bWEULIwGwkSap5xpYypqAA3n67J1Om/Ceff/45a9as4emnn6ZJkybst99+zJ07F4CHH36YPn360KxZswqX77vvvjRr1ox58+YB8Oijj9bYPkmSVFXeIK+MKCiA/gK3fIoAABRrSURBVP1h/fquhHAK7dp1pF27Q8nJyaFZs2Y8+OCD5TfCf/vb32by5MkAO1w+efLk8hvkBw4cWJO7JklSlYRMXPZJJScnJ26+wVq124QJcMMNUFIC9eqt4ac/bcrll39G7969uffee8nOzq7pKUqSlFQIoSjGmLPtci8jKiPy8qBhQ8jKghBGM3lyJ7Kzszn99NMNLUnSHs3LiMqI3FyYPRvy8yEv7w/k5tb0jCRJqh2MLWVMbi5GliRJ2/AyoiRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkLGliRJUkJViq0Qwv4hhOdCCEvL/t7vK8ZmhRBeDyHMqMo2JUmS6pKqntm6FpgdYzwMmF32ekcuBxZXcXuSJEl1SlVjaxDwYNnXDwKnVjQohPAt4PvA76u4PUmSpDqlqrF1UIxxOUDZ3wfuYNydwDXApipuT5IkqU6pv7MBIYRZwDcreOv6ymwghHAy8EGMsSiEkFeJ8aOB0QCHHHJIZTYhSZJUa+00tmKMx+3ovRDC/4UQWsYYl4cQWgIfVDCsB3BKCOEkYC9gnxDCIzHGITvY3r3AvQA5OTmxMjshSZJUW1X1MuJTwLCyr4cBT247IMY4Nsb4rRhjG+Ac4PkdhZYkSdLupqqxdRtwfAhhKXB82WtCCAeHEJ6p6uQkSZLqup1eRvwqMcYPgf4VLF8GnFTB8nwgvyrblCRJqkt8grwkSVJCxpYkSVJCxpYkSVJCxpYkSVJCxpYkSUrqzjvv5LPPPqvpadQYY0uSJCVlbEmSJGXI2rVr+f73v0/Hjh1p3749N998M8uWLaNv37707dsXgD/+8Y8cffTRtG/fnjFjxpR/b9OmTfnJT35CdnY2/fv3Z8WKFTW1GxllbEmSpIz5r//6Lw4++GDeeOMN3nzzTa644goOPvhgXnjhBV544QWWLVvGmDFjeP7551mwYAHz58/niSeeAEpDLTs7m9dee40+ffpw88031/DeZIaxJUmSMuboo49m1qxZjBkzhrlz59KsWbOt3p8/fz55eXm0aNGC+vXrc+655zJnzhwA6tWrx9lnnw3AkCFDmDdvXrXPP4UqPUFekiRpS9/73vcoKirimWeeYezYsQwYMGCr92OMlV5XCCHT06sRntmSJElVVlAAEybAU08to3HjxgwZMoSrrrqK1157jb333pvVq1cD0K1bN1588UVWrlxJSUkJf/zjH+nTpw8AmzZtYtq0aQD84Q9/oGfPnjW2P5nkmS1JklQlBQXQvz+sXw9ZWX+jdeuradq0Hg0aNOCee+6hoKCAE088kZYtW/LCCy8wYcIE+vbtS4yRk046iUGDBgHQpEkTFi1aRJcuXWjWrBlTp06t4T3LjPB1TudVt5ycnFhYWFjT06jT2rRpQ2FhIc2bN6/pqUiSdlMTJsANN0BJCWRlwfjxMHbs119P06ZNWbNmTeYnWE1CCEUxxpxtl3sZcTdWUlJS01OQJO0B8vKgYcPS0GrYsPS1vmRs1VI///nPueuuuwC48sor6devHwCzZ89myJAhX/mMkhtvvJFu3bpRUFBQvnzdunWccMIJ3HfffdW7I5Kk3V5uLsyeXXpGa/bs0te7oi6f1foqxlYt1bt3b+bOnQtAYWEha9asYcOGDcybN4/DDjvsK59R0r59e1555ZXyGwvXrFnDD37wA370ox8xatSoGtsnSdLuKze39NLhrobW7szYqqW6dOlCUVERq1ev5hvf+Aa5ubkUFhYyd+5c9t133x0+oyQrK4vTTz99q3UNGjSIESNGMHTo0JrYFUmS9mjGVi3VoEED2rRpw+TJk+nevTu9evXihRde4B//+AeHHHLIDr9vr732Iisra6tlPXr04Nlnn/1azzaRJEmZYWzVQpufVdK2bW9+8Ytf0Lt3b3r16sXEiRPp1KkTxx577A6fUVKRW265hQMOOICLLrqoGvdCkiSBsVXrbH5WyQ03wCOP9GLZsuXk5uZy0EEHsddee9GrVy9atmxZ/oySjh07kp2dXf6Mkh258847+fzzz7nmmmuqaU8kSRL4nK1aJ1PPKpEkSdXL52zVET6rRJKk3YuxVctsflZJVlbTKj2rZFvFxcW0b98+MyuTJEmVZmx9hRtvvJFZs2ZV+3Zzc6FBA59VIknS7sDY+gq33HILxx13XI3OIcbI1VdfTfv27Tn66KPLfynn2WefzTPPPFM+bvjw4UyfPp2SkhKuvvpqunbtSocOHfjd73633Tp79erFggULyl/36NGDhQsXpt8ZSZL2QMYWpZfYjjjiCEaNGsVRRx3FgAEDWLduHcOHD2fatGkAzJ8/n+7du9OxY0eOOeYYVq9eXamwqarHHnuMBQsW8MYbbzBr1iyuvvpqli9fzjnnnFMeXuvXr2f27NmcdNJJ3H///TRr1oz58+czf/587rvvPt55552t1jly5EgeeOABAJYsWcIXX3xBhw4dMj53SZJkbJVbunQpF198MYsWLWLfffdl+vTp5e+tX7+es88+m//4j/8oj55GjRpVKmyqat68eQwePJisrCwOOugg+vTpw/z58znxxBN5/vnn+eKLL3j22Wfp3bs3jRo1YubMmTz00EN06tSJbt268eGHH7J06dKt1nnmmWcyY8YMNmzYwKRJkxg+fHhG5yxJkr5Uv6YnUFu0bduWTp06AaW/Kqe4uLj8vbfeeouWLVvStWtXAPbZZx8AZs6cycKFC8vPfq1atYqlS5fStm3bjM1rR4/m2GuvvcjLy+Mvf/kLU6dOZfDgweXj7777bgYOHLjV+C33p3Hjxhx//PE8+eST/OlPf2JPe7yGJEnVyTNbZb7xjW+Uf52VlcXGjRvLX8cYCSFs9z2bw2bBggUsWLCAd955hwEDBlRpHpufHr9pU+nr3r17M3XqVEpKSlixYgVz5szhmGOOAeCcc85h8uTJzJ07tzyuBg4cyD333MOGDRuA0suEa9eu3W47I0eO5LLLLqNr167sv//+VZqzJEnasT36zFZBAeTnQ7t2Xz3u8MMPZ9myZcyfP5+uXbuyevVqGjVqVB42/fr1o0GDBixZsoRWrVrRpEmTXZ5P//6wfn3pQ00LCuC0006joKCAjh07EkLg5z//Od/85jcBGDBgAEOHDuWUU06hYcOGQGlEFRcXk52dTYyRFi1a8MQTT2y3rS5durDPPvswYsSIXZqrJEmqnD02trYMm/r14eCDdzy2YcOGTJ06lUsvvZR169bRqFEjZs2aVemwqaz8/C9DKytrDfn5kJsbuP3227n99tu3G9+gQQM+/PDDrZbVq1ePW2+9lVtvvXWr5c2aNePNN98sf71s2TI2bdpU5TNxkiTpq+2xsbVl2EAbRo36MkSuuuqq7cZ37dqVl19+ebvlFYXNrtr89Pj169M+Pf6hhx7i+uuv54477qBePa8kS5KU0h77uxG3PLPVsCEZfVp7VeeVn18aWrVhPpIkqXJ29LsR99gzW5t/LU5tC5vc3NozF0mSVHV7bGyBYSNJktLzhh1JkqSEjC1JkqSEjC1JkqSEjC1JkqSEjC1JkqSEjC1JkqSEjC1JkqSEjC1JkqSEjC1JkrSV4uJi2rdvX+3fu7sytiRJkhIytiRJ0nY2btzIsGHD6NChA2eccQafffYZt9xyC127dqV9+/aMHj2aGCMARUVFdOzYkdzcXH7zm9/U8MxrH2NLkiRt56233mL06NEsXLiQffbZh9/+9rdccsklzJ8/nzfffJN169YxY8YMAEaMGMFdd91FQUFBDc+6djK2JEnSdlq3bk2PHj0AGDJkCPPmzeOFF16gW7duHH300Tz//PMsWrSIVatW8cknn9CnTx8ADj/8cP75z3/W5NRrnfo1PQFJklT7hBC2e33RRRdRWFhI69atGTduHJ9//jkxxu3Gamue2ZIkSQAUFMCECfDaa/Duu+9SUFBAcXExp59+Oj179gTgkUce4brrruPhhx/mnnvu4cQTT+Szzz6jbdu2AMyaNQuATZs2cdhhh7FixYry19/97ndZuXJlzexcDfLMliRJoqAA+veH9euhfn1o0+YIHnzwQfLz8ykpKeHf/u3f+Pjjj/nlL3/JPvvsw8cff8wPf/hD7r//foYPH86UKVPIzc2lXbt2ANSrV48hQ4bw6KOPcsUVVzBr1iw6duxI8+bNa3hPq5+xJUmSyM8vDa2SEoA2jB79d8aOLX1u1sknn0zjxo356U9/yr777sv777/P448/zv333w/Aj3/8YwoLCykoKCA/P7/87NX555/PoEGDuOKKK5g0aRIjRoyosf2rSV5GlCRJ5OVBw4aQlVX6d15e6fL69euzadOm8nGb79OqjNatW3PQQQfx/PPP88orr3DiiSdmfuJ1gLElSZLIzYXZs2H8+NK/ofT+rXfeOYgPPviADz/8kC+++IIZM2aw3377sffee/Pyyy8DMGXKlB2ud+TIkQwZMoSzzjqLrKys6tiVWsfLiJIkCSgNrtzcre/fatiwARdccCPdunWjbdu2HH744QDcf//9jBo1iiZNmpCXl0ezZs0qXOcpp5zCiBEj9thLiGBsSZKkbWx5/9b69XDggZfx9tuXbTVmzZo1LFy4EIDbbruNnJwcAPLy8sjbfA0SeOONN+jYsWN5pO2JjC1JkrSVzfdvlZ7Z+vL+rS09/fTTTJgwgY0bN3LooYfywAMPbDfmtttu45577uHRRx9NPeVaLVT2JreakJOTEwsLC2t6GpIk7XEKCkrPcOXllV5a1M6FEIpijDnbLvfMliRJ2s7m+7dUdX4aUZIkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKSFjS5IkKaEQY6zpOexQCGEF8M9q3GRzYGU1bm9P4DHNPI9p5nlMM89jmnke08zL9DE9NMbYYtuFtTq2qlsIoTDGmFPT89ideEwzz2OaeR7TzPOYZp7HNPOq65h6GVGSJCkhY0uSJCkhY2tr99b0BHZDHtPM85hmnsc08zymmecxzbxqOabesyVJkpSQZ7YkSZIS2mNjK4SwfwjhuRDC0rK/99vBuH1DCNNCCP8dQlgcQsit7rnWJZU9rmVjs0IIr4cQZlTnHOuayhzTEELrEMILZT+ji0IIl9fEXGu7EMIJIYS3QghvhxCureD9EEK4q+z9hSGE7JqYZ11SiWN6btmxXBhC+GsIoWNNzLMu2dkx3WJc1xBCSQjhjOqcX11UmWMaQsgLISwo+3foi5nc/h4bW8C1wOwY42HA7LLXFfkP4L9ijIcDHYHF1TS/uqqyxxXgcjyelVGZY7oR+EmM8QjgWODiEMKR1TjHWi+EkAX8BjgROBIYXMExOhE4rOzPaOCeap1kHVPJY/oO0CfG2AEYj/cdfaVKHtPN4/4d+Ev1zrDuqcwxDSHsC/wWOCXGeBRwZibnsCfH1iDgwbKvHwRO3XZACGEfoDdwP0CMcX2M8ZNqm2HdtNPjChBC+BbwfeD31TSvumynxzTGuDzG+FrZ16spjdhW1TbDuuEY4O0Y4//EGNcDUyg9tlsaBDwUS70M7BtCaFndE61DdnpMY4x/jTF+XPbyZeBb1TzHuqYyP6cAlwLTgQ+qc3J1VGWO6Y+Ax2KM7wLEGDN6XPfk2DooxrgcSv9DBRxYwZhvAyuAyWWXu34fQmhSnZOsgypzXAHuBK4BNlXXxOqwyh5TAEIIbYDOwCvJZ1a3tALe2+L1+2wfpJUZoy993eP1/4Bnk86o7tvpMQ0htAJOAyZW47zqssr8nH4P2C+EkB9CKAohDM3kBOpncmW1TQhhFvDNCt66vpKrqA9kA5fGGF8JIfwHpZdwbsjQFOukqh7XEMLJwAcxxqIQQl4m51ZXZeBndfN6mlL6f7tXxBg/zcTcdiOhgmXbfhy7MmP0pUofrxBCX0pjq2fSGdV9lTmmdwJjYowlIVQ0XNuozDGtD3QB+gONgIIQwssxxiWZmMBuHVsxxuN29F4I4f9CCC1jjMvLLhNUdMrwfeD9GOPmMwTT+Op7kPYIGTiuPYBTQggnAXsB+4QQHokxDkk05VovA8eUEEIDSkPr0RjjY4mmWpe9D7Te4vW3gGW7MEZfqtTxCiF0oPSWgRNjjB9W09zqqsoc0xxgSlloNQdOCiFsjDE+UT1TrHMq+8/+yhjjWmBtCGEOpfdpZyS29uTLiE8Bw8q+HgY8ue2AGOP/Au+FENqVLeoP/L16pldnVea4jo0xfivG2AY4B3h+Tw6tStjpMQ2l/9a9H1gcY7yjGudWl8wHDgshtA0hNKT0Z++pbcY8BQwt+1TiscCqzZdwVaGdHtMQwiHAY8B5mTpLsJvb6TGNMbaNMbYp+3foNOAiQ+srVeaf/SeBXiGE+iGExkA3MvgBrj05tm4Djg8hLAWOL3tNCOHgEMIzW4y7FHg0hLAQ6ATcWu0zrVsqe1xVeZU5pj2A84B+ZR9dXlB25lBlYowbgUso/fTWYuBPMcZFIYQLQwgXlg17Bvgf4G3gPuCiGplsHVHJY3ojcADw27Kfy8Iamm6dUMljqq+hMsc0xrgY+C9gIfAq8PsY45uZmoNPkJckSUpoTz6zJUmSlJyxJUmSlJCxJUmSlJCxJUmSlJCxJUmSlJCxJUmSlJCxJUmSlJCxJUmSlND/BxMaOBCtSIY9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embd_matrix = embd.get_weights()[0]\n",
    "print(embd_matrix)\n",
    "plt.figure(figsize=(10,10))  \n",
    "for idx, (x1, x2) in enumerate(embd_matrix):\n",
    "    if idx == 0 : continue\n",
    "    plt.plot(x1, x2, 'b.')\n",
    "    plt.annotate(t.index_word[idx], (x1,x2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding Layer를 이용한 IMDB 텍스트 분류 실습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이타 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set : 25000, test set: (25000,), classes : 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "voca_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=voca_size)\n",
    "print(f'train set : {len(X_train)}, test set: {len(X_test), }, classes : {max(y_train)+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어-인덱스 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1\n"
     ]
    }
   ],
   "source": [
    "imdb_word_index = imdb.get_word_index()\n",
    "imdb_index_word = { idx : key for key, idx in imdb_word_index.items()}\n",
    "\n",
    "print(imdb_index_word[1], imdb_word_index['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이타 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0][:20])\n",
    "\n",
    "# 0:pad, 1:<start>, 2:UNK \n",
    "' '.join([imdb_index_word.get(i-3, '?') for i in X_train[0][:20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "max_len = 500\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 생성, 훈련, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 39s 2ms/sample - loss: 0.4619 - acc: 0.7776 - val_loss: 0.4323 - val_acc: 0.7946\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 38s 2ms/sample - loss: 0.2810 - acc: 0.8888 - val_loss: 0.3118 - val_acc: 0.8688\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 39s 2ms/sample - loss: 0.1878 - acc: 0.9290 - val_loss: 0.3479 - val_acc: 0.8660\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 39s 2ms/sample - loss: 0.1432 - acc: 0.9474 - val_loss: 0.4493 - val_acc: 0.8605\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 40s 2ms/sample - loss: 0.1142 - acc: 0.9581 - val_loss: 0.3961 - val_acc: 0.8683\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.1072 - acc: 0.9613 - val_loss: 0.4287 - val_acc: 0.8546\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0674 - acc: 0.9771 - val_loss: 0.5091 - val_acc: 0.8592\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0729 - acc: 0.9743 - val_loss: 0.6038 - val_acc: 0.8542\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0535 - acc: 0.9834 - val_loss: 0.6148 - val_acc: 0.8618\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0229 - acc: 0.9934 - val_loss: 0.6441 - val_acc: 0.8500\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0349 - acc: 0.9890 - val_loss: 0.7416 - val_acc: 0.8505\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0771 - acc: 0.9721 - val_loss: 0.5193 - val_acc: 0.8438\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0355 - acc: 0.9886 - val_loss: 0.6693 - val_acc: 0.8578\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0149 - acc: 0.9958 - val_loss: 0.7321 - val_acc: 0.8420\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0184 - acc: 0.9948 - val_loss: 0.7456 - val_acc: 0.8463\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0192 - acc: 0.9942 - val_loss: 0.7804 - val_acc: 0.8572\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0114 - acc: 0.9969 - val_loss: 0.8823 - val_acc: 0.8576\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0189 - acc: 0.9942 - val_loss: 0.7780 - val_acc: 0.8560\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 42s 2ms/sample - loss: 0.0346 - acc: 0.9892 - val_loss: 0.6767 - val_acc: 0.8521\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 41s 2ms/sample - loss: 0.0209 - acc: 0.9940 - val_loss: 0.7822 - val_acc: 0.8454\n",
      "25000/25000 [==============================] - 12s 496us/sample - loss: 0.7822 - acc: 0.8454\n",
      "cost :0.7821888622862101, accuracy:84.53599810600281%\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(voca_size, 250))\n",
    "model.add(tf.keras.layers.LSTM(120))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)\n",
    "\n",
    "result = model.evaluate(X_test, y_test)\n",
    "print(f'cost :{result[0]}, accuracy:{result[1] * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
